{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d186683-3968-49fc-999b-d0bb9a7faba0",
   "metadata": {},
   "source": [
    "**Q1. What is anomaly detection and what is its purpose?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b4891-2cf8-40c4-955e-9e6fd20cd7ab",
   "metadata": {},
   "source": [
    "Anomaly detection is the process of identifying data points that deviate significantly from the majority of the data. Its purpose is to detect unusual patterns that do not conform to expected behavior, which can indicate fraud, network intrusions, equipment failures, or other significant events.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98340d2-a553-4027-8eaa-a36061eed2ef",
   "metadata": {},
   "source": [
    "**Q2: What are the key challenges in anomaly detection?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2c06a-baf0-4c4d-aca7-a8c7a7f8f908",
   "metadata": {},
   "source": [
    "1. High Dimensionality: As the number of features increases, the data becomes sparse, making it difficult to identify anomalies.\n",
    "2. Imbalanced Data: Anomalies are often rare compared to normal instances, leading to challenges in training models effectively.\n",
    "3. Dynamic Environments: Anomalies can change over time, requiring models to adapt continuously.\n",
    "4. Noise in Data: Real-world data often contains noise, which can lead to false positives in anomaly detection.\n",
    "5. Lack of Labeled Data: Supervised methods require labeled data, which is often unavailable for anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f723d3-b70e-4e05-b2d7-785bf7efa96c",
   "metadata": {},
   "source": [
    "**Q3: How does unsupervised anomaly detection differ from supervised anomaly detection?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ffb79-7cd0-4bac-8937-5aede4c574f1",
   "metadata": {},
   "source": [
    "* Unsupervised Anomaly Detection: Does not rely on labeled data. It identifies anomalies based on the inherent structure of the data, using techniques like clustering or density estimation.\n",
    "* Supervised Anomaly Detection: Requires labeled data to train the model, where normal and anomalous instances are explicitly defined. It typically uses classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed202c-322c-410f-b62f-5f49ef0cfed9",
   "metadata": {},
   "source": [
    "**Q4: What are the main categories of anomaly detection algorithms?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d5261-9488-4d38-8954-40b5653f5314",
   "metadata": {},
   "source": [
    "1. Statistical Methods: Use statistical tests to identify anomalies based on probability distributions (e.g., Z-score, Grubbs' test).\n",
    "2. Machine Learning Methods:\n",
    "   * Supervised Learning: Algorithms like decision trees and SVMs trained on labeled data.\n",
    "   * Unsupervised Learning: Clustering algorithms (e.g., K-means, DBSCAN) and density-based methods.\n",
    "3. Distance-Based Methods: Identify anomalies based on distance metrics (e.g., K-Nearest Neighbors).\n",
    "4. Ensemble Methods: Combine multiple models to improve detection accuracy (e.g., Isolation Forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c48b5-1f3e-47ba-9ba4-537ee6760544",
   "metadata": {},
   "source": [
    "**Q5: What are the main assumptions made by distance-based anomaly detection methods?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f6d96-e6df-42aa-b02a-505005782cae",
   "metadata": {},
   "source": [
    "1. Locality: Anomalies are often located far from normal instances in the feature space.\n",
    "2. Density: Normal instances are densely packed, while anomalies are in sparse regions.\n",
    "3. Distance Metric: The choice of distance metric significantly affects the detection results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac804d-e257-4ad4-8390-a663be5c8e72",
   "metadata": {},
   "source": [
    "**Q6: How does the LOF algorithm compute anomaly scores?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3295dcc-1d3e-49a6-83ef-7aa5176d9a27",
   "metadata": {},
   "source": [
    "The Local Outlier Factor (LOF) algorithm computes anomaly scores based on the local density of data points. It compares the density of a point to the densities of its neighbors. If a point has a significantly lower density than its neighbors, it is considered an anomaly. The LOF score is calculated as follows:\n",
    "\n",
    "1. For each point, determine its k-nearest neighbors.\n",
    "2. Calculate the local reachability density (LRD) for each point.\n",
    "3. Compute the LOF score as the ratio of the average LRD of the point's neighbors to its own LRD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7f163-233e-4e3c-8faa-ded0c37a3fcd",
   "metadata": {},
   "source": [
    "**Q7: What are the key parameters of the Isolation Forest algorithm?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd2979-5dfc-4a05-8dd5-5b95a0b4e0ab",
   "metadata": {},
   "source": [
    "1. Number of Trees (n_estimators): The number of isolation trees to build. More trees can improve accuracy but increase computation time.\n",
    "2. Subsampling Size (max_samples): The number of samples to draw to train each tree. Smaller sizes can lead to faster training.\n",
    "3. Contamination: The proportion of outliers in the data, which helps in determining the threshold for anomaly scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
