{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b70ffd5-ce2a-4527-974a-be674ce5eef4",
   "metadata": {},
   "source": [
    "**Q1: What is Random Forest Regressor?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1126840f-6ec0-45cb-aef3-45dd3df12209",
   "metadata": {},
   "source": [
    "A Random Forest Regressor is an ensemble learning method used for regression tasks. It constructs multiple decision trees during training and outputs the mean prediction of the individual trees. This approach reduces overfitting and improves generalization compared to a single decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eaab56-5245-4fdb-bfee-f1e7ed6e740b",
   "metadata": {},
   "source": [
    "**Q2: How does Random Forest Regressor reduce the risk of overfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e90d56-491e-4a8b-b506-f1402a3fc9cd",
   "metadata": {},
   "source": [
    "Random Forest Regressor reduces the risk of overfitting by:\n",
    "\n",
    "* Bootstrap Aggregating (Bagging): It trains each decision tree on a random subset of the data, which ensures diversity among the trees.\n",
    "* Random Feature Selection: At each split in the tree, a random subset of features is chosen to determine the best split, which reduces the correlation between individual trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f308db-2a18-4d38-96c4-e0d203a576cf",
   "metadata": {},
   "source": [
    "**Q3: How does Random Forest Regressor aggregate the predictions of multiple decision trees?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a776fac6-a980-40e1-99e7-b4d19e471a4d",
   "metadata": {},
   "source": [
    "The Random Forest Regressor aggregates the predictions of multiple decision trees by averaging their outputs. For each data point, the regressor collects the predictions from all trees and computes the mean, which serves as the final prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4edcaa-2082-4ec4-a37d-323c6a36d0ac",
   "metadata": {},
   "source": [
    "**Q4: What are the hyperparameters of Random Forest Regressor?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d690e4f1-f9d2-4897-8d2a-9d4d8b129e8d",
   "metadata": {},
   "source": [
    "Key hyperparameters of Random Forest Regressor include:\n",
    "\n",
    "* n_estimators: The number of trees in the forest.\n",
    "* max_depth: The maximum depth of each tree.\n",
    "* min_samples_split: The minimum number of samples required to split an internal node.\n",
    "* min_samples_leaf: The minimum number of samples required to be at a leaf node.\n",
    "* max_features: The number of features to consider when looking for the best split.\n",
    "* bootstrap: Whether bootstrap samples are used when building trees.\n",
    "* random_state: Controls the randomness of the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecfaff-541d-4f56-b8a1-bbeb0d7ddebe",
   "metadata": {},
   "source": [
    "**Q5: What is the difference between Random Forest Regressor and Decision Tree Regressor?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b1da6-34d8-4c55-85ad-667098988f4a",
   "metadata": {},
   "source": [
    "* Ensemble vs Single Model: Random Forest Regressor is an ensemble method that builds multiple trees, whereas Decision Tree Regressor builds a single tree.\n",
    "* Overfitting: Random Forest Regressor tends to have lower variance and is less prone to overfitting compared to a single Decision Tree Regressor.\n",
    "* Prediction: Random Forest Regressor averages the predictions of all trees, while Decision Tree Regressor uses the prediction of one tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f052600-faaa-4c36-90a7-f0d81dc5e26d",
   "metadata": {},
   "source": [
    "**Q6: What are the advantages and disadvantages of Random Forest Regressor?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afac959-6a6c-4ec2-9e9e-05db8640c64d",
   "metadata": {},
   "source": [
    "`Advantages:`\n",
    "\n",
    "* Reduced Overfitting: Due to averaging multiple trees, it generalizes better.\n",
    "* Robustness: Handles large datasets with higher dimensionality well.\n",
    "* Feature Importance: Provides insights into feature importance.\n",
    "\n",
    "`Disadvantages:`\n",
    "\n",
    "* Complexity: Computationally more intensive than a single decision tree.\n",
    "* Interpretability: Harder to interpret the model compared to a single decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84337301-113c-451d-a0f4-b031693db7db",
   "metadata": {},
   "source": [
    "**Q7: What is the output of Random Forest Regressor?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610e8bd3-9300-4444-acb3-4728f1d245c0",
   "metadata": {},
   "source": [
    "The output of a Random Forest Regressor is a continuous value, which is the average of the predictions from all the decision trees in the forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d46ace-28de-47cc-987f-1ee0047f5800",
   "metadata": {},
   "source": [
    "**Q8: Can Random Forest Regressor be used for classification tasks?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b260ee04-2cdd-4428-af1c-8a15cfe890a8",
   "metadata": {},
   "source": [
    "No, Random Forest Regressor is specifically designed for regression tasks. However, there is a related model called Random Forest Classifier that is used for classification tasks. While the underlying principles are similar, the Random Forest Classifier aggregates the mode of the predictions for classification, rather than averaging the predictions as in regression.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
